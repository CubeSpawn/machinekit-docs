:ini: {basebackend@docbook:'':ini}
:hal: {basebackend@docbook:'':hal}
:ngc: {basebackend@docbook:'':ngc}
// begin a listing of ini/hal/ngc files like so:
//[source,{ini}]
//[source,{hal}]
//[source,{ngc}]

== Remapping Codes: A Short Tour of Internals

This section gives a an overview of the changes to the interpreter to
support remapped codes. It requires some familiarity with interpreter
internals. It is a bit of internals, a bit of white paper, and a bit
of narrative how the current solution came about.

== A short survey of interpreter execution
Before discussing remapping of codes it might be helpful to survey the
standard execution model of the interpreter as far as it relates to
remapping.

=== Task and Interpreter interaction, Queueing and Read-Ahead

The task part of EMC is responsible for coordinating actual machine
commands - movement, HAL interactions and so forth. It does not by
itself handle the RS274NGC language. To do so, task calls upon the
interpreter to parse and execute the next command - either from MDI or
the current file.

The interpreter execution generates canonical machine
operations. These are, however, not immediately executed but put on a queue. The
actual execution of these codes happens in the task part of EMC: canon
commands are pulled off that interpreter queue, and executed resulting
in actual machine movements.

This means that typically the interpreter is far ahead of the actual
execution of commands - the parsing of the program might well be
finished before any noticeable movement starts. This behaviour is
called 'read-ahead'.

However, some operations are incompatible with read-ahead - among them
such which, when executed, might change the program execution path or
parts of the world model. For instance, if execution depends on the
input value of a HAL pin, the interpreter needs to find out the actual
value of the pin to determine what to execute next - it cant just
'jump' past that HAL pin read operation and continue.

Therefore, when such a code is encountered, the interpreter returns a
special return code to task ('INTERP_EXECUTE_FINISH'). This signals to
task to stop readahead for now, and 'synchronize the world model with
the interpreter state'. In the context of the HAL pin example, this
means the actual value of the HAL pin is made avalable to the
interpreter. Now task can call the interpreter again to continue after
this 'HAL pin read' command, and since the actual value is now
available, parsing and execution can again run in parallel.

These commands are called "queue busters" and require special handling
by task, and in the interpreter. They are: 'Tool change', 'Waiting for
HAL input', and 'Probe'.

=== Interpreter state
Conceptually, the interpreter's state consist of variables which fall into
the following categories:

1. configuration information (typically from INI file)
2. the 'World model' - a representation of actual machine state
3. modal state
4. interpreter execution state

(3) refers to state which is 'carried over' between executing
individual NGC codes - for instance, once the spindle is turned on and
the speed is set, it remains at this setting until turned off. The
same goes for many codes, like feed, units and so forth.

(4) holds information about the block currently executed, wether we
are in a subroutine, interpreter variables etc.

Most of this state is aggregated in a - fairly incomprehensible and
unsystematic - structure _setup (see interp_internals.hh)

=== Word order and execution order

One or several 'words' may be present on an NGC 'block' if they are
compatible (some are mutually exclusive and must be on different
lines).  The execution model however prescribes a strict ordering of
execution of codes, regardless of their appearance on the source line
(<<sec:Order-of-Execution, G-Code Order of Execution>>).


=== Parsing

Once a line is read (in either MDI mode, or from the current NGC
file), it is parsed and flags and parameters are set in a 'struct
block' (struct _setup, member block1). This struct holds all information
about the current source line, but independent of different ordering
of codes on the current line: as long as several codes are compatible,
any source ordering will result in the same variables set in the
struct block. Right after parsing, all codes on a block are checked for
compatibility.

=== Execution

After successful parsing the block is executed by execute_block(), and
here the different items are handled according to execution order.

If a "queue buster" is found, a corresponding flag is set in the
interpreter state (toolchange_flag, input_flag, probe_flag) and the
interpreter returns an INTERP_EXECUTE_FINISH return value, signaling
'stop readahead for now, and resynch' to the caller ('task').
If no queue busters are found
after all items are executed, INTERP_OK is returned, signalling that
read-ahead may continue.

When read ahead continues after the synch, task starts executing
interpreter read() operations again.  During the next read operation,
the abovementioned flags are checked and corresponding variables are
set (because the a synch() was just executed, the values are now
current). This means that the next command already executes in the
properly set variable context.

=== Procedure execution

O-word procedures complicate handling of queue busters a bit. A queue
buster might be found somewhere in a nested procedure, resulting in a
semi-finished procedure call when INTERP_EXECUTE_FINISH is
returned. Task makes sure to synchronize the world model, and continue
parsing and execution as long as there is still a procedure executing
(call_level > 0).

== Remapping codes

What remapping really boils down to is to execute a NGC procedure
'spontanteously' in the proper context once a remapped word is
encountered *during execution*.

== Why the 'macro replacement' approach doesnt work

A simple, obvious and unfortunately defunct idea is 'macro expansion'
- for instance, assume as above that M400 would be mapped to
'myprocedure.ngc'. If codes could be treated like macros, expansion
during textual input looks promising at first look:

[source,{ngc}]
---------------------------------------------------------------------
; if the line reads like so:
M400
; just replace it by this:
o<myprocedure> call
---------------------------------------------------------------------
This scheme works only in a one-code-per line scenario; if multiple
codes were involved in a block, this fails because it's syntactically
invalid, as an O-word must be the only word on a line:

[source,{ngc}]
---------------------------------------------------------------------
; if the line reads like so:
T4 M6 M400 G91 G38.2 Z1
; just replace it by this?
T4 M6 o<myprocedure> call G91 G38.2 Z1
---------------------------------------------------------------------

Splitting these codes over several lines and insert the O-word
call accordingly does not work either because splitting codes over
several lines is not a semantically idempotent operation.

So, unfortunately macro expansion doesnt work - clearly a bigger hammer is needed.

== Current solution, part 1: Executing the replacement in the right moment

What would work is an approach which begins as follows:

- if a *new* code was defined, parsing (actually the appropriate 'item readers' like read_m() etc)
   will accept these codes  and record them in their respective modal group.
- a redefined *existing* code is treated in the item reader as before even if remapped.
- during block execution, items are processed in execution order.
- A remapped item will cause 'the replacment procedure to be executed' .

The last step sounds deceptively easy, unfortunately it's really hard. Let's see why:

Assume you are halfway through executing the items in a block, and
then a remapped item is discovered, causing a call to an O-word
procedure. So that implies constructing an appropriate call statement
like 'o<myprocedure> call', parse that and then execute the result
block. Unfortunately we werent done with executing the current block just yet - and
suddenly it got overwritten by the result of our spontaneous procedure
call.

So we really need a new block, or even better even a new interpreter
instance for that matter, and execute the replacement procedure in the
new interpreter instance, then throw it away. Sounds easy - let's
instantiate a new Interp() instance. That approach does not work either -
the current Interp() implementation can create multiple instances,
unfortunately they are useless for our problem because they all share
the same execution state - all Interp variables are static class variables
(!!). Result: new instance created, O-word call passed to the new
instance, dang - original block is again overwritten because it's a static
class variable.

== Nested remaps and the block stack requirement

So the obvious approach would be 'use a new block while executing the
replacement procedure'. This does work in principle, and I originally used
this approach. Unfortunately this breaks down in the face of nested remaps. Let's
see why - assume for example:

- our remapped code M400 has a replacement procedure rm400.ngc.
- rm400.ngc happens to call upon a different remapped code, like M401, which has replacement rm401.ngc
- rm401.ngc happens to call M402 ...

So to deal with nested remappings in the general case, we need a stack
of blocks currently executing a remap, just to keep track where we
are. This is what the current solution uses - it's the _setup.blocks
array (see src/emc/rs274ngc/interp_internal.hh)

There already is a procedure call stack, but it doesnt help for our
problem for two reasons: First, procedure call frames do not
carry blocks. That could be changed, but then not every procedure call
is caused by a remapped code, and not every remapped code might result
in a Oword procedure call (for instance, if we chose to execute a
predefined C or Python procedure, in which case the Oword call stack
is useless).

So the proper approach is to use a separate remapping stack, which is
actually a stack of blocks - because a remapping happens within the
context of a block. The block structure is extended by a few
variables to support remapping.

== The Block stack and execution paths

Before we had only a single block. Now we have the following setup:

- the 'controlling block' - which is is the one currently being stepped through item by item
- the 'executing block' - which is conceptually a local variable for the replacement NGC procedure.
- read() always fills in items into the executing block.
- execute() always works on the controlling block.
- in the trivial (non-remapped) case, controlling and executing block are identical ('execution as it always was')

The executing block is the bottom-of-stack element of the block
stack. Then, there's a remap stack pointer (_setup.remap_level) which
points to the controlling block. When a block contains no remapped
codes, then executing and controlling blocks are identical
(remap_level = 0).

When, after parsing and during execute() a block containing remappings is detected, the following happens:

- the executing block is pushed onto the block stack (duplicated) and remap_level increased by one. The top-of-stack block becomes the new controlling block.
- execute_block() as called by execute() works on this controlling block and steps through the items to
  be done.
- when execute_block() needs to execute an o-word call that is parsed into the executing block
- the controlling block is not disturbed during execution of the replacement procedure (which results
  in recursive call to execute())
- when we're done with executing the controlling block, the block stack pointer (remap_level) is reduced by one.

This scheme naturally handles nested remaps - the top-of-stack
always holds the innermost executing remap. So the above example of
nested remaps would result in the following stack layout (assume we
are currently executing the remap for M402):

    block containing remapped M402	<-- remap_level refers to this block
    block containing remapped M401
    block containing remapped M400
    executing block			<-- bottom of stack

== The re-execution requirement and the block execution trail

So by now we can handle nested remaps, and not trample upon the block
which contains a remapping, because we saved it onto the block
stack. What is still open is the execution of any other non-remapped
words in a block which contains one or several remapped items.

The way much of the code in interp_convert.cc is structured assumes
that a block may be executed through a single call to, say,
convert_m() or convert_g() even if several M- or G-codes are
present. Unfortunately, this assumption does not hold any more now
because we might be interrupted by dealing with a remapped code. And
when we're done with the remapped code, we need to step through the
rest of the controlling block to execute any leftover items.

There are really two options to handle this, an ugly and a nice one.

The ugly solution requires butchering up convert_m(), convert_g() and
others into one function per modal group, and 'remember where we were'
so we can continue execution when the current remap finishes.

The much nicer solution is to make execute_block() re-executable,
meaning no matter how many times we call upon execute_block() for a
given block, the result is always the same - all active items are executed
exactly once, even if execute_block() was interrupted by a remapped
operation. All that needs to be done is record an execution trail in
the block (a simple bit map which remembers which items were already
done - we 'tick them off' as we step through items). This is done with
the 'breadcrumbs' bitmap in struct block, and 'enum phases' which
names all the different items which could possibly be in a block and
need to be executed in sequence. To implement the 'exactly once'
semantics, the test-and-set macros ONCE() and ONCE_M() are used.

== Glue code: Prolog and Epilog functions
Now that the worst is over, the question of glue code needs to be addressed.

NGC code doesnt work well with its own interpreter internals. Looking
for example at the code handling an M6 you'll note it calls upon a
member function 'convert_tool_change'. Some of this is possible in
NGC, like spindle off, wiggle a HAL pin, move somewhere. Some stuff is
plain impossible, namely accessing interpreter state (like accessing
+settings->selected_pocket+ and setting +settings->current_pocket+).

In my original attempt I used hand-crafted C glue code to prepare
parameters for a limited set of remapped codes (Tx,M6,M61), and check
their return values after finishing the NGC procedure. That works, but doesnt
scale well when going for a generalized remapping solution which may
add arbitrary new codes to the interpreter - I didnt like the idea of
that - again - C code needs to be added just for functions which I
didnt perceive as necessary myselves, but other people might.

The basic scheme for calling a remap NGC procedure is always as follows:

- extract some values from interpreter state, like block or modal state, and prepare these as parameters for the NGC procedure (prolog)
- actually call the procedure
- evaluate any return codes and act accordingly (epilog)

For configurable glue code, I chose the solution to decorate remap
descriptions with optional prolog and epilog functions, which can be
referenced in the ini file. These prologs and epilogs are actually
Python functions (with the exception of the built-in +argspec+ prolog,
see below).

With this tool, it's possible to completely drop any C/C++ based glue
code and 'do it all in Python'. It might not be suited for the casual
script writer, but it is an fairly powerful extension tool.

Note that this is conceptually different from what user interfaces like Axis
or Touchy do - these are written in Python and call upon C code to access,
for instance, NML messages passed between components. This is called 'extending'
a Python interpreter by C code. My scheme uses 'Python embedding' - C code is
extended by optional Python procedures.

Since it occured to me one could write remap procedures now completely
in Python, not just as NGC procedures. This is in fact possible,
including handling of queue buster codes, which need special handling. See the exampke XXX.

Since queue busters interrupt a procedure, the procedure needs to be
called again after the interpreter synch(). So the procedure needs to
know if it is restarted, and where. This is achieved by a 'userdata'
 parameter. it is initially zero and always passed to a remapping
procedure. If the procedure needs to return INTERP_EXECUTE_FINISH
because of, say, reading a digital input it may return a new userdata
value along with the return code which is passed in on the next call.

Here's an example of reading a HAL pin in Python:

[source,python]
---------------------------------------------------------------------
# This demonstrates how queuebusters
# (toolchange, wait for input, probe) can be dealt with in Python handlers.
#
# activate by:
# [RS274NGC]
# REMAP=M402  modalgroup=10 py=test_reschedule
#
# on the initial call, userdata equals zero.
# if a queuebuster is executed, the function is expected to return
# (INTERP_EXECUTE_FINISH,<optional new userdata value>
#
# Post sync, the function is called again with the userdata value
# returned previously for continuation.
#
def test_reschedule(userdata,**words):
	if userdata > 0:
		# we were called post-sync():
		pin_status = CanonMod.GET_EXTERNAL_DIGITAL_INPUT(0,0);
		print "pin status=",pin_status
		return INTERP_OK # done
	else:
		# wait for digital-input 00 to go hi for 5secs
		CanonMod.WAIT(0,1,2,5.0)
		# pls call again after sync() with new userdata value
		return (INTERP_EXECUTE_FINISH, userdata + 1)
---------------------------------------------------------------------


== Embedded Python and Access to Interpreter and Canon

The current 'first cut' of extending the interpreter by embedded Python
functions provides access to most of the internal state, and some
important interpreter functions. Also, a module provides access to a
large part of the Canon layer from Python (actually it's the part
which was easy to do and it should be completed).

For access into the interpreter I used the 'boost.python' method of
using an embedded interpreter. This is some extremely powerful
C++/Python middleware which is much easier to use than the
Python/C-API. It is also already compatible with Python 3K.

The current state of the boost.python interface reflects my current
understanding of boost.python embedding, and not necessarily 'how it
should be done', but the dubious sections are fairly localized (mostly
access to the Interp instance pointer and _setup).

== The argspec prolog
The argspec prolog exists to simplify a common situation, namely passing word
parameters from the current block to the replacement procedure in an easy, standardized way.

A common case of argument handling is the following: A new code might:

- take zero or more required parameter words
- take zero or more optional parameter words
- ignore other parameter words on the same line
- require some standard precondition like feed greater than zero, or speed greater than zero

For this common case, there's the *argspec* builtin prolog. This enables parameter passing from the block which contains a remapped code, to a remap procedure as follows:

If an argspec=<string> is present in the REMAP line, it is treated as follows:

- any letters in the set 'abcdefhijkpqrstuvwxyz' designate parameter words.
- if the letter is uppercase, that word is required.
- if the letter is lowercase, that word is optional.
- a greater-sign  ('>') denotes 'requires feed greater than zero'
- a caret  ('^') denotes 'requires speed greater than zero'
- an at-sign ('@') denotes 'use positional parameters, not local variables' (see below)

The NGC procedure will then find the parameter words as local variables -
required parameters must be present, optional paramters may be tested
for by the 'EXISTS()' function.

Example:  [[G88.1-Remapping-example]]
[source,{ini}]
-------------------------------------------------------
[RS274NGC]
REMAP=G88.1  argspec=XYZpq  ngc=g881 modalgroup=1
-------------------------------------------------------

This means:

- Define the new code 'G88.1'
- execute 'G88.1' only if the +X+,+Y+ and +Z+ words are present in the current block
- *always* pass the values of +X+,+Y+ and +Z+ as parameters to the replacement procedure
- if the words +P+ and/or +Q+ are present, also pass their values as parameters
- the name of the replacement procedure to call is 'g881.ngc'
- execute this code as modal group 1, which refers to the sequencing order of several
 operations within a block.

Here's an example where we try to execute the newly-defined 'G88.1':
[source,{ngc}]
---------------------------------------------------------------------
G88.1 X1 Y2 P4     ; this fails because Z is required, but missing
G88.1 X1 Y2 Z3 P4  ; this calls g881.ngc since parameter words pass the argspec
---------------------------------------------------------------------

=== NGC procedures: Passing and accessing parameters
'argspec' defines a set of required and optional parameters for the remapped code.
These parameters may be passed to an NGC replacement procedure in the following ways:

1. as local named parameters (this is new)
2. as positional parameters (traditional method)

// make footnote
The reason for introducing a new method (1) for passing parameters to NGC procedures is twofold:

- with traditional positional parameters it is awkward to handle optional parameters - the NGC
procedure cannot tell wether, say, +#3+ was optional, or required, and which word it referred to
- named parameters provide better readability - for instance, the relation between variable +#<X>+ and
the +X+ word on the block is fairly obvious
- other than positional parameters, named parameters may exist, or not exist, and this can be
tested for with the 'EXISTS()' interpreter function, providing an elegant method to decide within the NGC
procedure wether an optional word was passed or not.

Method 2 (positional parameters) is kept around despite its limitations. Assume you have a useful
NGC procedure which you might want to wrap into a remapped code, like a canned cycle, and this procedure
takes a fixed number of parameters. In that case you can tell 'argspec' to provide a traditional positional
parameter list to the NGC procedure  by adding '@' to the argspec, see below - there's no need to rewrite
your procedure to refer to named parameters.

=== Passing parameters as local named variables to NGC procedures
Let's take the <<G88.1-Remapping-example,example>> from above, which specifies 'pass as local named parameters'
since it's the default method. It makes the passed parameters 'spring into existence' within the procedure
automatically.

The remap procedure may access parameter words as follows:

[source,{ngc}]
---------------------------------------------------------------------
o<g881> sub
(debug, g881: x=#<x> y=#<y> z=<z>) ; X,Y,Z must exist since they are required

; the optional P and Q words can be tested for with EXISTS:
o100 if [EXISTS[#<p>]]
     (debug, optional P word set: #<p>)
o100 endif

o200 if [EXISTS[#<q>]]
     (debug, optional Q word set: #<q>)
o200 endif

o<g881> endsub
m2
---------------------------------------------------------------------

=== Passing parameters as positional arguments to NGC procedures

To specify positional parameters, proceed as follows (note '@' in argspec):
[[G88.1-Remapping-example-positionalargs]]
[source,{ini}]
-------------------------------------------------------
[RS274NGC]
REMAP=G88.2  argspec=@PQr  ngc=g882 modalgroup=1
-------------------------------------------------------

This tells the interpreter to prepare arguments in the order specified, and pass them as positional arguments.
The required words +P+ and +Q+ would be mapped to +#1+ and +#2+ respectively. If an +R+ word was
present in the block, its value would be assigned to +#3+. Note that the default value of a parameter is '0',
so the NGC procedure would not be able to tell the difference between the two following statements:

[source,{ngc}]
---------------------------------------------------------------------
G88.2 P1 Q2     ;  #1 = 1, #2 = 2,  #3 is 0 (default parameter value)
G88.2 P1 Q2 R0  ;  #1 = 1, #2 = 2,  #3 is 0 (as assigned from R word)
---------------------------------------------------------------------

Note when using positional parameters with an '@' argspec, no named variables are set in the procedure.

=== Feed and Speed preconditions

If a remapped code assumes that the spindle is on, and/or the feed value needs to be greater than zero,
this can tested for with the argspec as follows:

- to require 'spindle on', specifiy the '^' (caret) argspec character
- to require 'feed greater than zero', specifiy the '>' (greater-sign) argspec character

Example:
[source,{ini}]
-------------------------------------------------------
[RS274NGC]
REMAP=M344  argspec=^> ngc=m344  modalgroup=9
-------------------------------------------------------

'm344.ngc' will be executed only if spindle is on, and feed is greater than zero, otherwise excecution will
fail with an appropriate error message.

=== Passing and evaluating return values from NGC remap procedures

In some cases, returning values from NGC procedures, and taking appropriate action is required.
Since NGC procedures may <<sec:Subroutine-return-values, optionally return a single float value>>,
this can be used to decide wether a remapped procedure failed, or succeeded, or take some other
action depending on the return value.

By default, NGC procedure return values are ignored. To handle a return value, a Python epilog
may be specified in the 'REMAP' statement:

[source,{ini}]
-------------------------------------------------------
[RS274NGC]
REMAP=M345  ngc=m345  epilog=demo_epilog modalgroup=9
-------------------------------------------------------

This refers to a Python function in the 'remap' module, which will be called after 'm345.ngc' finishes:

[source,python]
---------------------------------------------------------------------
# this example epilog looks at the return value from the NGC procedure
# and does the right thing:
def demo_epilog(userdata,**words):
	retval = interp.return_value
	if retval > 0:
		# let remapped code succeed if return value positive
		return INTERP_OK
	else:
		# fail remapped code with an error message
		interp.set_errormsg("M345: aborted (return value %.4f)" % (retval))
		return INTERP_ERROR
---------------------------------------------------------------------

== Passing parameters to Python functions

If the remap procedure is a Python function, it receives parameters
through the *words* dictionary:

Example:
[source,{ini}]
-------------------------------------------------------
[RS274NGC]
REMAP=G88.6 modalgroup=1  argspec=XYZp-  python=g886
-------------------------------------------------------

[source,python]
---------------------------------------------------------------------
def g886(userdata,**words):
    if (words.has_key('r')):
       print "r = ", words['r']
    CanonMod.STRAIGHT_TRAVERSE(InterpMod.interp.sequence_number(),
			   words['x'],words['y'],words['z'],
			   0,0,0,0,0,0)
---------------------------------------------------------------------

== Returning values from Python remap procedures
foo
== Advanced Prologs and Epilogs: Accessing interpreter internals
foo

== Organisation of Python plugin modules

// == Configuring remaps: the REMAP line

//== Lessons learned
